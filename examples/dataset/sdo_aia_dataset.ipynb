{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e6d6d8",
   "metadata": {},
   "source": [
    "# SunPy Maps: SDO/AIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911cb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sunpy.map\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sdoml import SDOMLDataset\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e222e7",
   "metadata": {},
   "source": [
    "### Instantiate the `SDOMLDataset` class\n",
    "\n",
    "First, we will instantiate the ``SDOMLDataset`` class, to load one month of \n",
    "the six optically-thin SDO/AIA channels (94A/131A/171A/193A/211A/335A) \n",
    "from ``fdl-sdoml-v2/sdomlv2_small.zarr``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb207eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdomlds = SDOMLDataset(\n",
    "    cache_max_size=1 * 512 * 512 * 4096,\n",
    "    years=[\n",
    "        \"2010\",\n",
    "    ],\n",
    "    data_to_load={\n",
    "        \"AIA\": {\n",
    "            \"storage_location\": \"gcs\",\n",
    "            \"root\": \"fdl-sdoml-v2/sdomlv2_small.zarr\",\n",
    "            \"channels\": [\"94A\", \"131A\", \"171A\", \"193A\", \"211A\", \"335A\"],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356ffc0",
   "metadata": {},
   "source": [
    "### Call the torch Dataloader\n",
    "\n",
    "With the Dataset instantiated, while we could directly access the dataset using the ``__getitem__`` method ( ``sdomlds.__getitem__(idx)`` loads and returns single sample from the dataset at the given index ``idx``), we will use the ``torch.utils.data.DataLoader`` iterator with a ``batch_size`` of 1, and no shuffling of the data.\n",
    "\n",
    "As will be evident, the first data access for a given chunk is relatively slow (it is retrieved from remote store on Google Cloud Storage), however the second data access is faster, as this uses cache. For more information see https://zarr.readthedocs.io/en/stable/api/storage.html#zarr.storage.LRUStoreCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a849d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    sdomlds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c745ef4",
   "metadata": {},
   "source": [
    "#### Loading one set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1d496",
   "metadata": {},
   "source": [
    "``SDOMLDataset()`` returns both image, and metadata as a single dictionary:\n",
    "\n",
    "```\n",
    "In:  data.keys()\n",
    "Out: dict_keys(['data', 'meta'])\n",
    "```\n",
    "\n",
    "* The ``images`` returned by ``__getitem__(idx)`` for a single observations is of size: ``(1, 6, 512, 512)``, where each item contains of the 6 requested co-temporal observations (SDO/AIA ``[94, 131, 171, 193, 211, 335]``) of ``torch.Size([512, 512])``. \n",
    "\n",
    "```\n",
    "In:  data['data'].keys()\n",
    "Out: dict_keys(['AIA'])\n",
    "In:  data['data']['AIA'].shape\n",
    "Out: torch.Size([1, 6, 512, 512])\n",
    "```\n",
    "\n",
    "* The ``metadata`` for AIA is a list of ``str(dictionary)``, each with 175 key-value pairs. EVE is stored similarly, with each dictionary containing 3 key-value pairs. As shown below, the length of these data is 64.\n",
    "\n",
    "```\n",
    "In:  data['meta'].keys()\n",
    "Out: dict_keys(['AIA'])\n",
    "In:  len(data['meta']['AIA'])\n",
    "Out: 1\n",
    "```\n",
    "\n",
    "A small excerpt of the AIA dictionary (for index 0 in the batch of 64) is shown below for ``['DEG_COR', 'EXPTIME', 'WAVELNTH', 'T_OBS']``.\n",
    "\n",
    "\n",
    "```\n",
    "> batch_index = 0\n",
    "> data['data']['AIA'][batch_index].shape\n",
    "torch.Size([6, 512, 512])\n",
    "\n",
    "> ast.literal_eval(data['meta']['AIA'][batch_index])\n",
    "\n",
    "{\n",
    "    ...\n",
    "    'DEG_COR': [1.083, 0.950019, 0.99739, 0.99217, 0.982774, 0.901734],\n",
    "    'EXPTIME': [2.901124, 2.901351, 1.999653, 2.000068, 2.900861, 2.900854],\n",
    "    'WAVELNTH': [94, 131, 171, 193, 211, 335],\n",
    "    'T_OBS': ['2010-08-01T00:00:09.57Z',\n",
    "              '2010-08-01T00:00:11.07Z',\n",
    "              '2010-08-01T00:00:01.34Z',\n",
    "              '2010-08-01T00:00:08.84Z',\n",
    "              '2010-08-01T00:00:02.07Z',\n",
    "              '2010-08-01T00:00:05.07Z']\n",
    "    ...\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "where a single key can be accessed:\n",
    "\n",
    "```\n",
    "In:  ast.literal_eval(data['meta']['AIA'][batch_index])['DEG_COR']\n",
    "Out: [1.083, 0.950019, 0.99739, 0.99217, 0.982774, 0.901734]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d2349",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "For the 211A channel, returned from the dataloader, the following code block creates a ``sunpy.map`` from the ``images`` and ``metadata``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb1c79",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "inst_num = 4\n",
    "selected_image = data[\"data\"][\"AIA\"][0, inst_num, :, :]\n",
    "selected_headr = {\n",
    "    keys: values[inst_num]\n",
    "    for keys, values in ast.literal_eval(data[\"meta\"][\"AIA\"][0]).items()\n",
    "}\n",
    "\n",
    "sunpy.map.Map(selected_image.numpy(), selected_headr).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b23ca",
   "metadata": {},
   "source": [
    "Similarly, as above, we can plot all of the loaded AIA channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "i = 0\n",
    "# iterate through instruments (here there is only AIA data)\n",
    "for inst in data[\"data\"]:\n",
    "    # iterate through the various channels for the given batch index\n",
    "    for img_index in range(data[\"data\"][inst][0, :, 0, 0].shape[0]):\n",
    "        # Create a sunpy map with the data\n",
    "        selected_image = data[\"data\"][inst][0, img_index, :, :]\n",
    "        selected_headr = {\n",
    "            keys: values[img_index]\n",
    "            for keys, values in ast.literal_eval(data[\"meta\"][inst][0]).items()\n",
    "        }\n",
    "        my_map = sunpy.map.Map(selected_image.numpy(), selected_headr)\n",
    "\n",
    "        # set the index and plot the sunpy.map\n",
    "        ax = plt.subplot(2, 3, i + 1, projection=my_map)\n",
    "        my_map.plot()\n",
    "\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
